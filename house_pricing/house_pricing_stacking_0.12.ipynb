{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import zipfile\n",
    "from statsmodels.tsa.deterministic import DeterministicProcess, CalendarFourier\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('C:/Users/Serueja/Downloads/house-prices-advanced-regression-techniques.zip')\n",
    "test = pd.read_csv(zf.open('test.csv'))\n",
    "train = pd.read_csv(zf.open('train.csv'))\n",
    "train.drop(['Id'], axis=1, inplace=True)\n",
    "test.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['SalePrice'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train.GrLivArea < 4500]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "y = train['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.drop(['SalePrice'], axis=1)\n",
    "test_features = test\n",
    "features = pd.concat([train_features, test_features]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 79)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['MSSubClass'] = features['MSSubClass'].apply(str)\n",
    "features['YrSold'] = features['YrSold'].astype(str)\n",
    "features['MoSold'] = features['MoSold'].astype(str)\n",
    "\n",
    "\n",
    "features['Functional'] = features['Functional'].fillna('Typ') \n",
    "features['Electrical'] = features['Electrical'].fillna(\"SBrkr\") \n",
    "features['KitchenQual'] = features['KitchenQual'].fillna(\"TA\") \n",
    "features[\"PoolQC\"] = features[\"PoolQC\"].fillna(\"None\")\n",
    "\n",
    "\n",
    "features['Exterior1st'] = features['Exterior1st'].fillna(features['Exterior1st'].mode()[0]) \n",
    "features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])\n",
    "features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "    features[col] = features[col].fillna(0)\n",
    "\n",
    "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
    "    features[col] = features[col].fillna('None')\n",
    "\n",
    "    \n",
    "### Same with basement\n",
    "\n",
    "for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "    features[col] = features[col].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code will filll the missing values with the mode (The frequently category appearing) By each MSsubclass:\n",
    "# Idea is that similar MSSubClasses will have similar MSZoning\n",
    "\n",
    "features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "objects = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype == object:\n",
    "        objects.append(i)\n",
    "features.update(features[objects].fillna('None'))\n",
    "print(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics.append(i)\n",
    "features.update(features[numerics].fillna(0))\n",
    "numerics[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\stats\\_stats_py.py:4098: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficient may be inaccurate.\n",
      "  warnings.warn(PearsonRNearConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "for i in features.columns:\n",
    "    if features[i].dtype in numeric_dtypes:\n",
    "        numerics2.append(i)\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "\n",
    "for i in skew_index:\n",
    "    features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "# Adding new features . Make sure that you understand this. \n",
    "\n",
    "features['YrBltAndRemod']=features['YearBuilt']+features['YearRemodAdd']\n",
    "features['TotalSF']=features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']\n",
    "\n",
    "features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] +\n",
    "                                 features['1stFlrSF'] + features['2ndFlrSF'])\n",
    "\n",
    "features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) +\n",
    "                               features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))\n",
    "\n",
    "features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] +\n",
    "                              features['EnclosedPorch'] + features['ScreenPorch'] +\n",
    "                              features['WoodDeckSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2917, 333)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features = pd.get_dummies(features).reset_index(drop=True)\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1458, 333), (1458,), (1459, 333))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = final_features.iloc[:len(y), :]\n",
    "X_sub = final_features.iloc[len(y):, :]\n",
    "X.shape, y.shape, X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass_150']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = [30, 88, 462, 631, 1322]\n",
    "X = X.drop(X.index[outliers])\n",
    "y = y.drop(y.index[outliers])\n",
    "\n",
    "overfit = []\n",
    "for i in X.columns:\n",
    "    counts = X[i].value_counts()\n",
    "    zeros = counts.iloc[0]\n",
    "    if zeros / len(X) * 100 > 99.94:\n",
    "        overfit.append(i)\n",
    "\n",
    "overfit = list(overfit)\n",
    "X = X.drop(overfit, axis=1)\n",
    "X_sub = X_sub.drop(overfit, axis=1)\n",
    "overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining error functions for handy use. \n",
    "\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(alphas=alphas2, random_state=42, cv=kfolds))\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                                       num_leaves=4,\n",
    "                                       learning_rate=0.01, \n",
    "                                       n_estimators=5000,\n",
    "                                       max_bin=200, \n",
    "                                       bagging_fraction=0.75,\n",
    "                                       bagging_freq=5, \n",
    "                                       bagging_seed=7,\n",
    "                                       feature_fraction=0.2,\n",
    "                                       feature_fraction_seed=7,\n",
    "                                       verbose=-1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
    "                                     max_depth=3, min_child_weight=0,\n",
    "                                     gamma=0, subsample=0.7,\n",
    "                                     colsample_bytree=0.7,\n",
    "                                     objective='reg:linear', nthread=-1,\n",
    "                                     scale_pos_weight=1, seed=27,\n",
    "                                     reg_alpha=0.00006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.053029921142874414, tolerance: 0.019178268998164005\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.15725973107340874, tolerance: 0.019137348670505955\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.030393270628383817, tolerance: 0.01920076813324067\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18426881715129007, tolerance: 0.017898055875660616\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6704235570787445, tolerance: 0.017963971190360983\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.021959710052321668, tolerance: 0.019739406477929166\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO: 0.1002 (0.0142)\n",
      " 2022-09-20 19:46:53.938003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1963450630033936, tolerance: 0.017963971190360983\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13117764898562445, tolerance: 0.017963971190360983\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.026370730266584097, tolerance: 0.017963971190360983\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic net: 0.1002 (0.0143)\n",
      " 2022-09-20 19:47:27.563295\n",
      "SVR: 0.1016 (0.0130)\n",
      " 2022-09-20 19:47:32.659033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "lightgbm: 0.1065 (0.0154)\n",
      " 2022-09-20 19:48:03.162524\n",
      "gbr: 0.1089 (0.0158)\n",
      " 2022-09-20 19:50:00.045498\n",
      "[19:50:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:50:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:50:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:50:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:50:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:51:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:51:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:51:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:51:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:52:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "xgboost: 0.1044 (0.0153)\n",
      " 2022-09-20 19:52:18.033866\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(ridge , X)\n",
    "score = cv_rmse(lasso , X)\n",
    "print(\"LASSO: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(elasticnet)\n",
    "print(\"elastic net: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )\n",
    "\n",
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()), datetime.now(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START Fit\n",
      "stack_gen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26959682297009735, tolerance: 0.016792229167400276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017336993314251536, tolerance: 0.017093096531483772\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Serueja\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.10103321835877566, tolerance: 0.016575503005326092\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:54:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:54:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:55:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:55:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[19:55:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[19:56:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "elasticnet\n",
      "Lasso\n",
      "Ridge\n",
      "Svr\n",
      "GradientBoosting\n",
      "xgboost\n",
      "[19:56:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "lightgbm\n"
     ]
    }
   ],
   "source": [
    "print('START Fit')\n",
    "\n",
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(X, y)\n",
    "\n",
    "print('elasticnet')\n",
    "elastic_model_full_data = elasticnet.fit(X, y)\n",
    "\n",
    "print('Lasso')\n",
    "lasso_model_full_data = lasso.fit(X, y)\n",
    "\n",
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, y)\n",
    "\n",
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, y)\n",
    "\n",
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, y)\n",
    "\n",
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, y)\n",
    "\n",
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
    "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.3 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.05551323562535698\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y, blend_models_predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict submission\n"
     ]
    }
   ],
   "source": [
    "print('Predict submission')\n",
    "submission = pd.read_csv(zf.open('sample_submission.csv'))\n",
    "submission.iloc[:,1] = (np.expm1(blend_models_predict(X_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = submission['SalePrice'].quantile(0.0042)\n",
    "q2 = submission['SalePrice'].quantile(0.99)\n",
    "# Quantiles helping us get some extreme values for extremely low or high values \n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "submission['SalePrice'] = submission['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)\n",
    "submission.to_csv(\"submission_stacking.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b024f8da0c8551bbbf35191ef2c39e7fe2117f57d174045348ded50d165655c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
